use crate::{Error, Result};
use async_trait::async_trait;
use moka::future::Cache as MokaCache;
use redis::AsyncCommands;
use serde::{de::DeserializeOwned, Serialize};
use std::sync::Arc;
use std::time::Duration;

/// ç¼“å­˜é”®
pub type CacheKey = String;

/// ç¼“å­˜å±‚trait
#[async_trait]
pub trait CacheLayer: Send + Sync {
    /// è·å–ç¼“å­˜å€¼
    async fn get<T: DeserializeOwned + Send>(&self, key: &str) -> Result<Option<T>>;

    /// è®¾ç½®ç¼“å­˜å€¼
    async fn set<T: Serialize + Send + Sync>(
        &self,
        key: &str,
        value: &T,
        ttl: Duration,
    ) -> Result<()>;

    /// åˆ é™¤ç¼“å­˜
    async fn delete(&self, key: &str) -> Result<()>;

    /// æ‰¹é‡è·å–
    async fn get_many<T: DeserializeOwned + Send>(
        &self,
        keys: &[&str],
    ) -> Result<Vec<Option<T>>>;

    /// æ‰¹é‡è®¾ç½®
    async fn set_many<T: Serialize + Send + Sync>(
        &self,
        items: &[(&str, &T, Duration)],
    ) -> Result<()>;

    /// ç¼“å­˜å±‚åç§°
    fn name(&self) -> &str;
}

/// L1: å†…å­˜ç¼“å­˜ï¼ˆä½¿ç”¨mokaï¼‰
pub struct L1MemoryCache {
    cache: MokaCache<String, Vec<u8>>,
    name: String,
}

impl L1MemoryCache {
    /// åˆ›å»ºæ–°çš„å†…å­˜ç¼“å­˜
    ///
    /// # å‚æ•°
    /// - `max_capacity`: æœ€å¤§å®¹é‡ï¼ˆæ¡ç›®æ•°ï¼‰
    /// - `default_ttl`: é»˜è®¤TTL
    pub fn new(max_capacity: u64, default_ttl: Duration) -> Self {
        let cache = MokaCache::builder()
            .max_capacity(max_capacity)
            .time_to_live(default_ttl)
            .build();

        Self {
            cache,
            name: "L1-Memory".to_string(),
        }
    }

    /// åˆ›å»ºé»˜è®¤é…ç½®ï¼ˆ10000æ¡ç›®ï¼Œ30ç§’TTLï¼‰
    pub fn default() -> Self {
        Self::new(10_000, Duration::from_secs(30))
    }
}

#[async_trait]
impl CacheLayer for L1MemoryCache {
    async fn get<T: DeserializeOwned + Send>(&self, key: &str) -> Result<Option<T>> {
        match self.cache.get(&key.to_string()).await {
            Some(bytes) => {
                let value: T = bincode::deserialize(&bytes)
                    .map_err(|e| Error::Internal(format!("L1 deserialize error: {}", e)))?;
                tracing::trace!("L1 HIT: {}", key);
                Ok(Some(value))
            }
            None => {
                tracing::trace!("L1 MISS: {}", key);
                Ok(None)
            }
        }
    }

    async fn set<T: Serialize + Send + Sync>(
        &self,
        key: &str,
        value: &T,
        _ttl: Duration,
    ) -> Result<()> {
        let bytes = bincode::serialize(value)
            .map_err(|e| Error::Internal(format!("L1 serialize error: {}", e)))?;

        self.cache.insert(key.to_string(), bytes).await;
        tracing::trace!("L1 SET: {}", key);
        Ok(())
    }

    async fn delete(&self, key: &str) -> Result<()> {
        self.cache.invalidate(&key.to_string()).await;
        tracing::trace!("L1 DELETE: {}", key);
        Ok(())
    }

    async fn get_many<T: DeserializeOwned + Send>(
        &self,
        keys: &[&str],
    ) -> Result<Vec<Option<T>>> {
        let mut results = Vec::with_capacity(keys.len());
        for key in keys {
            results.push(self.get(key).await?);
        }
        Ok(results)
    }

    async fn set_many<T: Serialize + Send + Sync>(
        &self,
        items: &[(&str, &T, Duration)],
    ) -> Result<()> {
        for (key, value, ttl) in items {
            self.set(key, value, *ttl).await?;
        }
        Ok(())
    }

    fn name(&self) -> &str {
        &self.name
    }
}

/// L2: Redisç¼“å­˜
pub struct L2RedisCache {
    client: Arc<redis::Client>,
    name: String,
}

impl L2RedisCache {
    /// åˆ›å»ºæ–°çš„Redisç¼“å­˜
    ///
    /// # å‚æ•°
    /// - `redis_url`: Redisè¿æ¥URL
    pub async fn new(redis_url: &str) -> Result<Self> {
        let client = redis::Client::open(redis_url)
            .map_err(|e| Error::Internal(format!("Redis connection error: {}", e)))?;

        // æµ‹è¯•è¿æ¥
        let mut conn = client
            .get_multiplexed_async_connection()
            .await
            .map_err(|e| Error::Internal(format!("Redis connection test failed: {}", e)))?;

        // Pingæµ‹è¯•
        redis::cmd("PING")
            .query_async::<_, String>(&mut conn)
            .await
            .map_err(|e| Error::Internal(format!("Redis ping failed: {}", e)))?;

        Ok(Self {
            client: Arc::new(client),
            name: "L2-Redis".to_string(),
        })
    }
}

#[async_trait]
impl CacheLayer for L2RedisCache {
    async fn get<T: DeserializeOwned + Send>(&self, key: &str) -> Result<Option<T>> {
        let mut conn = self
            .client
            .get_multiplexed_async_connection()
            .await
            .map_err(|e| Error::Internal(format!("Redis connection error: {}", e)))?;

        let bytes: Option<Vec<u8>> = conn
            .get(key)
            .await
            .map_err(|e| Error::Internal(format!("Redis get error: {}", e)))?;

        match bytes {
            Some(bytes) => {
                let value: T = bincode::deserialize(&bytes)
                    .map_err(|e| Error::Internal(format!("L2 deserialize error: {}", e)))?;
                tracing::trace!("L2 HIT: {}", key);
                Ok(Some(value))
            }
            None => {
                tracing::trace!("L2 MISS: {}", key);
                Ok(None)
            }
        }
    }

    async fn set<T: Serialize + Send + Sync>(
        &self,
        key: &str,
        value: &T,
        ttl: Duration,
    ) -> Result<()> {
        let mut conn = self
            .client
            .get_multiplexed_async_connection()
            .await
            .map_err(|e| Error::Internal(format!("Redis connection error: {}", e)))?;

        let bytes = bincode::serialize(value)
            .map_err(|e| Error::Internal(format!("L2 serialize error: {}", e)))?;

        conn.set_ex(key, bytes, ttl.as_secs() as u64)
            .await
            .map_err(|e| Error::Internal(format!("Redis set error: {}", e)))?;

        tracing::trace!("L2 SET: {} (TTL: {}s)", key, ttl.as_secs());
        Ok(())
    }

    async fn delete(&self, key: &str) -> Result<()> {
        let mut conn = self
            .client
            .get_multiplexed_async_connection()
            .await
            .map_err(|e| Error::Internal(format!("Redis connection error: {}", e)))?;

        conn.del(key)
            .await
            .map_err(|e| Error::Internal(format!("Redis delete error: {}", e)))?;

        tracing::trace!("L2 DELETE: {}", key);
        Ok(())
    }

    async fn get_many<T: DeserializeOwned + Send>(
        &self,
        keys: &[&str],
    ) -> Result<Vec<Option<T>>> {
        let mut conn = self
            .client
            .get_multiplexed_async_connection()
            .await
            .map_err(|e| Error::Internal(format!("Redis connection error: {}", e)))?;

        let bytes_vec: Vec<Option<Vec<u8>>> = redis::cmd("MGET")
            .arg(keys)
            .query_async(&mut conn)
            .await
            .map_err(|e| Error::Internal(format!("Redis mget error: {}", e)))?;

        let mut results = Vec::with_capacity(bytes_vec.len());
        for bytes_opt in bytes_vec {
            match bytes_opt {
                Some(bytes) => {
                    let value: T = bincode::deserialize(&bytes).map_err(|e| {
                        Error::Internal(format!("L2 batch deserialize error: {}", e))
                    })?;
                    results.push(Some(value));
                }
                None => results.push(None),
            }
        }

        Ok(results)
    }

    async fn set_many<T: Serialize + Send + Sync>(
        &self,
        items: &[(&str, &T, Duration)],
    ) -> Result<()> {
        let mut conn = self
            .client
            .get_multiplexed_async_connection()
            .await
            .map_err(|e| Error::Internal(format!("Redis connection error: {}", e)))?;

        // ä½¿ç”¨pipelineæ‰¹é‡è®¾ç½®
        let mut pipe = redis::pipe();
        for (key, value, ttl) in items {
            let bytes = bincode::serialize(value)
                .map_err(|e| Error::Internal(format!("L2 batch serialize error: {}", e)))?;
            pipe.set_ex(*key, bytes, ttl.as_secs() as u64);
        }

        pipe.query_async(&mut conn)
            .await
            .map_err(|e| Error::Internal(format!("Redis pipeline error: {}", e)))?;

        Ok(())
    }

    fn name(&self) -> &str {
        &self.name
    }
}

/// åˆ†å±‚ç¼“å­˜ç®¡ç†å™¨
///
/// æŒ‰ç…§L1(å†…å­˜) -> L2(Redis) -> L3(æ•°æ®æº)çš„é¡ºåºæŸ¥æ‰¾
///
/// # ç‰¹æ€§
/// - è‡ªåŠ¨å›å¡«ï¼šL2å‘½ä¸­æ—¶è‡ªåŠ¨å›å¡«L1
/// - æ‰¹é‡æ“ä½œæ”¯æŒ
/// - ç¼“å­˜ç©¿é€ä¿æŠ¤
/// - ç»Ÿè®¡ä¿¡æ¯æ”¶é›†
pub struct TieredCacheManager {
    l1: Arc<dyn CacheLayer>,
    l2: Arc<dyn CacheLayer>,
    l1_ttl: Duration,
    l2_ttl: Duration,
    stats: Arc<tokio::sync::RwLock<CacheStats>>,
}

/// ç¼“å­˜ç»Ÿè®¡
#[derive(Debug, Clone, Default)]
pub struct CacheStats {
    pub l1_hits: u64,
    pub l1_misses: u64,
    pub l2_hits: u64,
    pub l2_misses: u64,
    pub total_requests: u64,
}

impl CacheStats {
    pub fn l1_hit_rate(&self) -> f64 {
        if self.total_requests == 0 {
            return 0.0;
        }
        self.l1_hits as f64 / self.total_requests as f64
    }

    pub fn l2_hit_rate(&self) -> f64 {
        if self.total_requests == 0 {
            return 0.0;
        }
        self.l2_hits as f64 / self.total_requests as f64
    }

    pub fn overall_hit_rate(&self) -> f64 {
        if self.total_requests == 0 {
            return 0.0;
        }
        (self.l1_hits + self.l2_hits) as f64 / self.total_requests as f64
    }
}

impl TieredCacheManager {
    /// åˆ›å»ºæ–°çš„åˆ†å±‚ç¼“å­˜ç®¡ç†å™¨
    ///
    /// # å‚æ•°
    /// - `l1`: L1ç¼“å­˜å±‚ï¼ˆå†…å­˜ï¼‰
    /// - `l2`: L2ç¼“å­˜å±‚ï¼ˆRedisï¼‰
    /// - `l1_ttl`: L1ç¼“å­˜TTL
    /// - `l2_ttl`: L2ç¼“å­˜TTL
    pub fn new(
        l1: Arc<dyn CacheLayer>,
        l2: Arc<dyn CacheLayer>,
        l1_ttl: Duration,
        l2_ttl: Duration,
    ) -> Self {
        Self {
            l1,
            l2,
            l1_ttl,
            l2_ttl,
            stats: Arc::new(tokio::sync::RwLock::new(CacheStats::default())),
        }
    }

    /// åˆ›å»ºé»˜è®¤é…ç½®
    ///
    /// L1: 30ç§’ï¼ŒL2: 120ç§’
    pub async fn with_default_config(redis_url: &str) -> Result<Self> {
        let l1 = Arc::new(L1MemoryCache::default());
        let l2 = Arc::new(L2RedisCache::new(redis_url).await?);

        Ok(Self::new(
            l1,
            l2,
            Duration::from_secs(30),
            Duration::from_secs(120),
        ))
    }

    /// è·å–ç¼“å­˜å€¼
    ///
    /// æŸ¥æ‰¾é¡ºåºï¼šL1 -> L2 -> è¿”å›None
    /// å¦‚æœL2å‘½ä¸­ï¼Œè‡ªåŠ¨å›å¡«L1
    pub async fn get<T: DeserializeOwned + Serialize + Send + Sync + Clone>(
        &self,
        key: &str,
    ) -> Result<Option<T>> {
        // æ›´æ–°ç»Ÿè®¡
        {
            let mut stats = self.stats.write().await;
            stats.total_requests += 1;
        }

        // 1. å°è¯•L1
        if let Some(value) = self.l1.get::<T>(key).await? {
            let mut stats = self.stats.write().await;
            stats.l1_hits += 1;
            return Ok(Some(value));
        }

        // L1 miss
        {
            let mut stats = self.stats.write().await;
            stats.l1_misses += 1;
        }

        // 2. å°è¯•L2
        if let Some(value) = self.l2.get::<T>(key).await? {
            // L2å‘½ä¸­ï¼Œå›å¡«L1
            if let Err(e) = self.l1.set(key, &value, self.l1_ttl).await {
                tracing::warn!("Failed to backfill L1 cache: {}", e);
            }

            let mut stats = self.stats.write().await;
            stats.l2_hits += 1;
            return Ok(Some(value));
        }

        // L2 miss
        {
            let mut stats = self.stats.write().await;
            stats.l2_misses += 1;
        }

        Ok(None)
    }

    /// è®¾ç½®ç¼“å­˜å€¼
    ///
    /// åŒæ—¶å†™å…¥L1å’ŒL2
    pub async fn set<T: Serialize + Send + Sync>(&self, key: &str, value: &T) -> Result<()> {
        // å†™å…¥L1ï¼ˆå¿½ç•¥é”™è¯¯ï¼‰
        if let Err(e) = self.l1.set(key, value, self.l1_ttl).await {
            tracing::warn!("Failed to set L1 cache: {}", e);
        }

        // å†™å…¥L2
        self.l2.set(key, value, self.l2_ttl).await?;

        Ok(())
    }

    /// åˆ é™¤ç¼“å­˜
    ///
    /// åŒæ—¶åˆ é™¤L1å’ŒL2
    pub async fn delete(&self, key: &str) -> Result<()> {
        // åˆ é™¤L1ï¼ˆå¿½ç•¥é”™è¯¯ï¼‰
        if let Err(e) = self.l1.delete(key).await {
            tracing::warn!("Failed to delete from L1: {}", e);
        }

        // åˆ é™¤L2
        self.l2.delete(key).await?;

        Ok(())
    }

    /// æ‰¹é‡è·å–
    pub async fn get_many<T: DeserializeOwned + Serialize + Send + Sync + Clone>(
        &self,
        keys: &[&str],
    ) -> Result<Vec<Option<T>>> {
        let mut results = Vec::with_capacity(keys.len());
        let mut l2_needed_indices = Vec::new();
        let mut l2_needed_keys = Vec::new();

        // 1. æ‰¹é‡æŸ¥è¯¢L1
        let l1_results = self.l1.get_many::<T>(keys).await?;

        for (i, result) in l1_results.into_iter().enumerate() {
            match result {
                Some(value) => {
                    results.push(Some(value));
                }
                None => {
                    results.push(None);
                    l2_needed_indices.push(i);
                    l2_needed_keys.push(keys[i]);
                }
            }
        }

        // 2. L1æœªå‘½ä¸­çš„ï¼ŒæŸ¥è¯¢L2
        if !l2_needed_keys.is_empty() {
            let l2_results = self.l2.get_many::<T>(&l2_needed_keys).await?;

            for (idx_in_l2, &idx_in_results) in l2_needed_indices.iter().enumerate() {
                if let Some(value) = &l2_results[idx_in_l2] {
                    // L2å‘½ä¸­ï¼Œå›å¡«L1
                    if let Err(e) = self.l1.set(keys[idx_in_results], value, self.l1_ttl).await {
                        tracing::warn!("Failed to backfill L1 in batch: {}", e);
                    }
                    results[idx_in_results] = Some(value.clone());
                }
            }
        }

        Ok(results)
    }

    /// æ‰¹é‡è®¾ç½®
    pub async fn set_many<T: Serialize + Send + Sync>(
        &self,
        items: &[(&str, &T)],
    ) -> Result<()> {
        let l1_items: Vec<(&str, &T, Duration)> = items
            .iter()
            .map(|(k, v)| (*k, *v, self.l1_ttl))
            .collect();

        let l2_items: Vec<(&str, &T, Duration)> = items
            .iter()
            .map(|(k, v)| (*k, *v, self.l2_ttl))
            .collect();

        // å†™å…¥L1ï¼ˆå¿½ç•¥é”™è¯¯ï¼‰
        if let Err(e) = self.l1.set_many(&l1_items).await {
            tracing::warn!("Failed to batch set L1: {}", e);
        }

        // å†™å…¥L2
        self.l2.set_many(&l2_items).await?;

        Ok(())
    }

    /// è·å–æˆ–è®¾ç½®ï¼ˆä½¿ç”¨æä¾›çš„å‡½æ•°è·å–å€¼ï¼‰
    ///
    /// å¦‚æœç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨fetcherè·å–å€¼å¹¶ç¼“å­˜
    pub async fn get_or_fetch<T, F, Fut>(
        &self,
        key: &str,
        fetcher: F,
    ) -> Result<T>
    where
        T: DeserializeOwned + Serialize + Send + Sync + Clone,
        F: FnOnce() -> Fut,
        Fut: std::future::Future<Output = Result<T>>,
    {
        // å°è¯•ä»ç¼“å­˜è·å–
        if let Some(value) = self.get(key).await? {
            return Ok(value);
        }

        // ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨fetcher
        let value = fetcher().await?;

        // å†™å…¥ç¼“å­˜ï¼ˆå¼‚æ­¥ï¼Œä¸ç­‰å¾…ï¼‰
        let cache = self.clone_for_async();
        let key = key.to_string();
        let value_clone = value.clone();
        tokio::spawn(async move {
            if let Err(e) = cache.set(&key, &value_clone).await {
                tracing::warn!("Failed to cache fetched value: {}", e);
            }
        });

        Ok(value)
    }

    /// è·å–ç»Ÿè®¡ä¿¡æ¯
    pub async fn get_stats(&self) -> CacheStats {
        self.stats.read().await.clone()
    }

    /// æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    pub async fn log_stats(&self) {
        let stats = self.stats.read().await;

        tracing::info!(
            "ğŸ“Š Cache Stats: L1 hit rate: {:.1}%, L2 hit rate: {:.1}%, Overall: {:.1}% (total: {} requests)",
            stats.l1_hit_rate() * 100.0,
            stats.l2_hit_rate() * 100.0,
            stats.overall_hit_rate() * 100.0,
            stats.total_requests
        );
    }

    /// é‡ç½®ç»Ÿè®¡
    pub async fn reset_stats(&self) {
        let mut stats = self.stats.write().await;
        *stats = CacheStats::default();
    }

    /// å…‹éš†ç”¨äºå¼‚æ­¥æ“ä½œ
    fn clone_for_async(&self) -> Self {
        Self {
            l1: Arc::clone(&self.l1),
            l2: Arc::clone(&self.l2),
            l1_ttl: self.l1_ttl,
            l2_ttl: self.l2_ttl,
            stats: Arc::clone(&self.stats),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_cache_stats() {
        let mut stats = CacheStats::default();
        stats.total_requests = 100;
        stats.l1_hits = 60;
        stats.l1_misses = 40;
        stats.l2_hits = 25;
        stats.l2_misses = 15;

        assert_eq!(stats.l1_hit_rate(), 0.6);
        assert_eq!(stats.l2_hit_rate(), 0.25);
        assert_eq!(stats.overall_hit_rate(), 0.85);
    }

    #[tokio::test]
    async fn test_l1_memory_cache() {
        let cache = L1MemoryCache::new(100, Duration::from_secs(60));

        // Test set and get
        cache
            .set("test_key", &"test_value".to_string(), Duration::from_secs(60))
            .await
            .unwrap();

        let value: Option<String> = cache.get("test_key").await.unwrap();
        assert_eq!(value, Some("test_value".to_string()));

        // Test delete
        cache.delete("test_key").await.unwrap();
        let value: Option<String> = cache.get("test_key").await.unwrap();
        assert_eq!(value, None);
    }

    #[tokio::test]
    async fn test_l1_batch_operations() {
        let cache = L1MemoryCache::new(100, Duration::from_secs(60));

        // Batch set
        let items = vec![
            ("key1", &1u64, Duration::from_secs(60)),
            ("key2", &2u64, Duration::from_secs(60)),
            ("key3", &3u64, Duration::from_secs(60)),
        ];
        cache.set_many(&items).await.unwrap();

        // Batch get
        let results: Vec<Option<u64>> = cache.get_many(&["key1", "key2", "key3"]).await.unwrap();
        assert_eq!(results, vec![Some(1), Some(2), Some(3)]);
    }

    #[test]
    fn test_l1_cache_name() {
        let cache = L1MemoryCache::default();
        assert_eq!(cache.name(), "L1-Memory");
    }
}
